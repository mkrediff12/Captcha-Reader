{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport os\nimport glob\nimg_dir = '/kaggle/input/captcha-dataset/train_image/train' # Enter Directory of all images \ndata_path = os.path.join(img_dir,'*.png')\nfiles = glob.glob(data_path)\ndata = []    #contain train_img\nfor f1 in files:\n    img = cv2.imread(f1)\n    data.append(img)\ntrain_wrds_label=[]   #contains train_img words name corresponding to train_img \nfor dirname, _, filenames in os.walk('/kaggle/input/captcha-dataset/train_image/train'):\n    for filename in filenames:\n        train_wrds_label.append(filename.split(\".\")[0])\n\n    # len(data)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(nrows = 5, ncols = 1, figsize = (5, 5))\nfor i in range(0, 5 ):\n    ax = axs[i]\n    ax.imshow(data[i])                \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len_wrds=[]\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/captcha-dataset/train_image/train'):\n    for filename in filenames:\n        len_wrds.append(len(filename)-4)\nprint(len_wrds)     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\ndirname = 'train_img.png'\nos.mkdir(dirname)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"contours_no=[]\nidx=-1\nfor img in data:\n    idx=idx+1\n    img_rgb=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img_gray=cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n    _, thresh_img = cv2.threshold(img_gray, 127, 255, cv2.THRESH_BINARY)\n    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n    morph_img = cv2.morphologyEx(thresh_img, cv2.MORPH_CLOSE, kernel)\n    contours, hierarchy = cv2.findContours(\n                                   image = morph_img, \n                                   mode = cv2.RETR_TREE, \n                                   method = cv2.CHAIN_APPROX_SIMPLE)\n    \n    contours_new=[]\n    threshold_area = 1300    #threshold area    \n    \n    for cnt in contours:        \n        area = cv2.contourArea(cnt)         \n        if area > threshold_area:                   \n             contours_new.append(cnt)\n    \n    # Draw the contour \n    img_copy = img_rgb.copy()\n    final = cv2.drawContours(img_copy, contours_new, contourIdx = -1, \n                         color = (255, 0, 0), thickness = 2)\n\n    \n    img_copy = img_rgb.copy()\n    \n    cnt_rect=[]  #contour rectangles\n    \n    for c in contours_new:\n        x,y,w,h=cv2.cv2.boundingRect(c)\n        if(w<120 and h>65 and h<110):\n            cnt_rect.append((x,y,w,h))\n#             img_box = cv2.rectangle(img_copy, (x-5, y-5), (x+w+5, y+h+5), color = (255, 0, 0), thickness = 2)\n#     removing the rectangles inside bigger rectangle leaving only the bigges rectangle\n    \n    rcr=[] #real contour rectangles afterremoving several inner rectangles from outer\n    \n    for i in cnt_rect:\n        flag=0\n        for j in cnt_rect:\n                if((i[0]>j[0]) and (i[0]+i[2])<(j[0]+j[2]) and (i[1]>j[1]) and (i[1]+i[3])<(j[1]+j[3])):\n                    flag=1\n                    break\n        if flag==0:\n            rcr.append(i)\n     \n    rcr=sorted(rcr, key=lambda a: a[0]) #sorting contour rectangles wrt to x so that we get letters according the order on which they originally are  \n    contours_no.append(len(rcr)) \n#     img_copy = img_rgb.copy()\n#     for c in rcr:\n#         (x,y,w,h)= c\n#         img_box = cv2.rectangle(img_copy, (x-10, y-10), (x+w+10, y+h+10), color = (255, 0, 0), thickness = 2) \n    if contours_no[idx]==len_wrds[idx]: \n        letter_img=[]\n        i=0\n        for box in rcr:\n            letter_img.append(img_copy[box[1]:box[1]+box[3],box[0]:box[0]+box[2]])\n            img=letter_img[i]\n#             img_i = Image.fromarray(letter_img[i], 'RGB')\n#             img_i.save(os.path.join(dirname, train_wrds_label[idx] + str(i)), 'png')\n            cv2.imwrite(os.path.join(dirname, train_wrds_label[idx] + str(i)), img)\n            i=i+1\n            \n#     fig, axs = plt.subplots(nrows = 1, ncols = len(letter_img), figsize = (20, 20))\n#     for i in range(0, len(letter_img) ):\n#         ax = axs[i]\n#         ax.imshow(letter_img[i])    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(contours_no)\n# len(contours_no)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking how much image have correct no of contour rectangles\nc=0\nd=0\nf=0\nidx=[]\nfor i in range(0,1500):\n    if(contours_no[i]==len_wrds[i]):\n        c=c+1\n        idx.append(i)\n    if(contours_no[i]>len_wrds[i]):\n        d=d+1\n#         idx.append(i)\n    if(contours_no[i]<len_wrds[i]):\n        f=f+1    \n#         idx.append(i)\nprint(c,d,f,c+d+f)  \n# print(idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = cv2.imread('train_img.png/AAE0')\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #for deleting a directory\n# import sys\n# import shutil\n# shutil.rmtree('test_img.png')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Preparing training data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"cnt = 0\nacc = 0\nx_train = []\ny_train = []\nlabel = 0\nfiles = []\npath = 'train_img.png/'\n# r=root, d=directories, f = files\nfor r, d, f in os.walk(path):\n    for file in f:\n        files.append(file)\n        # print(file)\n        gray = cv2.imread(path + file)\n        gray = cv2.cvtColor(gray, cv2.COLOR_BGR2GRAY)\n        gray = cv2.resize(255-gray, (100, 100))\n        x_train.append(gray)\n        y_train.append(file[int(file[-1])])\n                ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = np.array(x_train)\ny_train = np.array(y_train)\nprint(x_train.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(y_train[10])\n# plt.imshow(x_train[10],cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train=pd.get_dummies(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.isnull()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train=pd.DataFrame(y_train).to_numpy()\nx_train = x_train.reshape(x_train.shape[0], 100, 100, 1)\nx_train = x_train.astype('float32')\nx_train = x_train/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(x_train)\n# print(y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**TRAINING MODEL AND PREDICTING**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# USING CNN\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers. normalization import BatchNormalization\nimport tensorflow as tf\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(50, kernel_size = (3, 3), activation='relu', input_shape=(100, 100, 1)))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, kernel_size=(3,3), activation='softmax'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='softmax'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, kernel_size=(3,3), activation='softmax'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\n# model.add(Conv2D(96, kernel_size=(3,3), activation='softmax'))\n# model.add(MaxPooling2D(pool_size=(2,2)))\n# model.add(BatchNormalization())\nmodel.add(Dropout(0.2))\nmodel.add(Flatten())\n# model.add(Dense(256, activation='sigmoid'))\nmodel.add(Dense(128, activation='sigmoid'))\nmodel.add(Dense(64, activation='sigmoid'))\n#model.add(Dropout(0.3))\nmodel.add(Dense(26, activation = 'sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_train, y_train, batch_size = 50, epochs = 10, verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preparing test data for calculation of accuracy of correct no of letters predicted(doing same stuff as before)\nimport cv2\nimport os\nimport glob\nimg_dir = '/kaggle/input/captcha-dataset/test_image/test' # Enter Directory of all images \ndata_path = os.path.join(img_dir,'*.png')\nfiles = glob.glob(data_path)\ndata = []    #contain train_img\nfor f1 in files:\n    img = cv2.imread(f1)\n    data.append(img)\ntest_wrds_label=[]   #contains train_img words name corresponding to train_img \nfor dirname, _, filenames in os.walk('/kaggle/input/captcha-dataset/test_image/test'):\n    for filename in filenames:\n        test_wrds_label.append(filename.split(\".\")[0])\n\n    # len(data)    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len_wrds=[]\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/captcha-dataset/test_image/test'):\n    for filename in filenames:\n        len_wrds.append(len(filename)-4)\nprint(len_wrds)     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\ndirname = 'test_img.png'\nos.mkdir(dirname)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"contours_no=[]\nidx=-1\nfor img in data:\n    idx=idx+1\n    img_rgb=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img_gray=cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n    _, thresh_img = cv2.threshold(img_gray, 127, 255, cv2.THRESH_BINARY)\n    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n    morph_img = cv2.morphologyEx(thresh_img, cv2.MORPH_CLOSE, kernel)\n    contours, hierarchy = cv2.findContours(\n                                   image = morph_img, \n                                   mode = cv2.RETR_TREE, \n                                   method = cv2.CHAIN_APPROX_SIMPLE)\n    \n    contours_new=[]\n    threshold_area = 1300    #threshold area    \n    \n    for cnt in contours:        \n        area = cv2.contourArea(cnt)         \n        if area > threshold_area:                   \n             contours_new.append(cnt)\n    \n    # Draw the contour \n    img_copy = img_rgb.copy()\n    final = cv2.drawContours(img_copy, contours_new, contourIdx = -1, \n                         color = (255, 0, 0), thickness = 2)\n\n    \n    img_copy = img_rgb.copy()\n    \n    cnt_rect=[]  #contour rectangles\n    \n    for c in contours_new:\n        x,y,w,h=cv2.cv2.boundingRect(c)\n        if(w<120 and h>65 and h<110):\n            cnt_rect.append((x,y,w,h))\n#             img_box = cv2.rectangle(img_copy, (x-5, y-5), (x+w+5, y+h+5), color = (255, 0, 0), thickness = 2)\n#     removing the rectangles inside bigger rectangle leaving only the bigges rectangle\n    \n    rcr=[] #real contour rectangles afterremoving several inner rectangles from outer\n    \n    for i in cnt_rect:\n        flag=0\n        for j in cnt_rect:\n                if((i[0]>j[0]) and (i[0]+i[2])<(j[0]+j[2]) and (i[1]>j[1]) and (i[1]+i[3])<(j[1]+j[3])):\n                    flag=1\n                    break\n        if flag==0:\n            rcr.append(i)\n     \n    rcr=sorted(rcr, key=lambda a: a[0]) #sorting contour rectangles wrt to x so that we get letters according the order on which they originally are  \n    contours_no.append(len(rcr)) \n#     img_copy = img_rgb.copy()\n#     for c in rcr:\n#         (x,y,w,h)= c\n#         img_box = cv2.rectangle(img_copy, (x-10, y-10), (x+w+10, y+h+10), color = (255, 0, 0), thickness = 2) \n    if contours_no[idx]==len_wrds[idx]: \n        letter_img=[]\n        i=0\n        for box in rcr:\n            letter_img.append(img_copy[box[1]:box[1]+box[3],box[0]:box[0]+box[2]])\n            img=letter_img[i]\n#             img_i = Image.fromarray(letter_img[i], 'RGB')\n#             img_i.save(os.path.join(dirname, train_wrds_label[idx] + str(i)), 'png')\n            cv2.imwrite(os.path.join(dirname, test_wrds_label[idx] + str(i)), img)\n            i=i+1\n            \n#     fig, axs = plt.subplots(nrows = 1, ncols = len(letter_img), figsize = (20, 20))\n#     for i in range(0, len(letter_img) ):\n#         ax = axs[i]\n#         ax.imshow(letter_img[i])    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnt = 0\nacc = 0\nx_test = []\ny_test = []\nlabel = 0\nfiles = []\ni=0\npath = 'test_img.png/'\n# r=root, d=directories, f = files\nfor r, d, f in os.walk(path):\n    for file in f:\n        files.append(file)\n        # print(file)\n        gray = cv2.imread(path + file)\n        gray = cv2.cvtColor(gray, cv2.COLOR_BGR2GRAY)\n        gray = cv2.resize(255-gray, (100, 100))\n        x_test.append(gray)\n        y_test.append(file[int(file[-1])])\n        i=i+1        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = np.array(x_test)\ny_test = np.array(y_test)\nprint(x_test.shape)\nprint(y_test.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test=pd.get_dummies(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.isnull()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test=pd.DataFrame(y_test).to_numpy()\nprint(y_test)\n# plt.imshow(x_test.reshape(x_test.shape[0],100,100))\nx_test = x_test.reshape(x_test.shape[0], 100, 100, 1)\nx_test = x_test.astype('float32')\nx_test = x_test/255\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test[0].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, acc = model.evaluate(x_test, y_test, verbose = 1)\nprint(acc * 100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = model.predict(x_test)\nacc=0\nprint(len(y_pred))\nfor i in range(len(y_pred)):\n#     print(chr(y_test[i].argmax()+65))\n#     print(chr(y_pred[i].argmax()+65))\n    if y_test[i].argmax()==y_pred[i].argmax():\n        acc=acc+1\n\nprint(acc/len(y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculation accuracy by counting total LCS(longest common subsequence)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preparing test data for calculation of accuracy of correct no of letters predicted(doing same stuff as before)\nimport cv2\nimport os\nimport glob\nimg_dir = '/kaggle/input/captcha-dataset/test_image/test' # Enter Directory of all images \ndata_path = os.path.join(img_dir,'*.png')\nfiles = glob.glob(data_path)\ndata = []    #contain train_img\nfor f1 in files:\n    img = cv2.imread(f1)\n    data.append(img)\ntest_wrds_label=[]   #contains train_img words name corresponding to train_img \nfor dirname, _, filenames in os.walk('/kaggle/input/captcha-dataset/test_image/test'):\n    for filename in filenames:\n        test_wrds_label.append(filename.split(\".\")[0])\n\n    # len(data)    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len_wrds=[]\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/captcha-dataset/test_image/test'):\n    for filename in filenames:\n        len_wrds.append(len(filename)-4)\nprint(len_wrds)     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#LCS algorithm\ndef lcs( str1, str2, p, q ):\n    if p == 0 or q == 0:\n        return 0\n    elif str1[p-1] == str2[q-1]:\n        return 1 + lcs( str1, str2, p - 1, q - 1 )\n    else:\n        return max( lcs( str1, str2, p - 1, q ), lcs( str1, str2, p, q - 1 ) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"contours_no=[]\nidx=-1\nacc_1=0\nacc_2=0\ntotal_letters_test=0\nfor img in data:\n    idx=idx+1\n    img_rgb=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img_gray=cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n    _, thresh_img = cv2.threshold(img_gray, 127, 255, cv2.THRESH_BINARY)\n    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n    morph_img = cv2.morphologyEx(thresh_img, cv2.MORPH_CLOSE, kernel)\n    contours, hierarchy = cv2.findContours(\n                                   image = morph_img, \n                                   mode = cv2.RETR_TREE, \n                                   method = cv2.CHAIN_APPROX_SIMPLE)\n    \n    contours_new=[]\n    threshold_area = 1300    #threshold area    \n    \n    for cnt in contours:        \n        area = cv2.contourArea(cnt)         \n        if area > threshold_area:                   \n             contours_new.append(cnt)\n    \n    # Draw the contour \n    img_copy = img_rgb.copy()\n    final = cv2.drawContours(img_copy, contours_new, contourIdx = -1, \n                         color = (255, 0, 0), thickness = 2)\n\n    \n    img_copy = img_rgb.copy()\n    \n    cnt_rect=[]  #contour rectangles\n    \n    for c in contours_new:\n        x,y,w,h=cv2.cv2.boundingRect(c)\n        if(w<120 and h>65 and h<110):\n            cnt_rect.append((x,y,w,h))\n#             img_box = cv2.rectangle(img_copy, (x-5, y-5), (x+w+5, y+h+5), color = (255, 0, 0), thickness = 2)\n#     removing the rectangles inside bigger rectangle leaving only the bigges rectangle\n    \n    rcr=[] #real contour rectangles afterremoving several inner rectangles from outer\n    \n    for i in cnt_rect:\n        flag=0\n        for j in cnt_rect:\n                if((i[0]>j[0]) and (i[0]+i[2])<(j[0]+j[2]) and (i[1]>j[1]) and (i[1]+i[3])<(j[1]+j[3])):\n                    flag=1\n                    break\n        if flag==0:\n            rcr.append(i)\n     \n    rcr=sorted(rcr, key=lambda a: a[0]) #sorting contour rectangles wrt to x so that we get letters according the order on which they originally are  \n    contours_no.append(len(rcr)) \n#     img_copy = img_rgb.copy()\n#     for c in rcr:\n#         (x,y,w,h)= c\n#         img_box = cv2.rectangle(img_copy, (x-10, y-10), (x+w+10, y+h+10), color = (255, 0, 0), thickness = 2)  \n    letter_img=[]\n    i=0\n    str=[]\n    s=\"\"\n    for box in rcr:\n        letter_img.append(img_copy[box[1]:box[1]+box[3],box[0]:box[0]+box[2]])\n        img=letter_img[i]\n        total_letters_test+=1\n#         cv2.imwrite(os.path.join(dirname, test_wrds_label[idx] + str(i)), img)\n        i=i+1\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        gray = cv2.resize(255-gray, (100, 100))\n        x_test=np.array(gray)\n        x_test = x_test.reshape(1,100, 100,1)\n        x_test = x_test.astype('float32')\n        x_test = x_test/255\n        y_pred=model.predict(x_test)\n        y_pred=chr(y_pred.argmax()+65)\n        str.append(y_pred)\n    s=s.join(str)\n#     print(s,test_wrds_label[idx])\n    if s==test_wrds_label[idx]:\n        acc_1+=1\n    \n    acc_2=acc_2+lcs(s,test_wrds_label[idx],len(s),len(test_wrds_label[idx]))\n    \n            \n#     fig, axs = plt.subplots(nrows = 1, ncols = len(letter_img), figsize = (20, 20))\n#     for i in range(0, len(letter_img) ):\n#         ax = axs[i]\n#         ax.imshow(letter_img[i])    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculating accuracy according to no of captcha predicted correct\nacc_1=acc_1/500*100 \nprint(acc_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#calculating accuracy according to LCS\nacc_2=acc_2/total_letters_test*100\nprint(acc_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}